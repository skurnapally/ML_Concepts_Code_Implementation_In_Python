{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOoWtI/arzJc0WjXIdlcz4e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# lets implement linear regression from scratch\n"],"metadata":{"id":"HP-px_tj2qht"}},{"cell_type":"markdown","source":["## import section"],"metadata":{"id":"OSa0jhti23gv"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"7FU6C9FV2lW8","executionInfo":{"status":"ok","timestamp":1666248674713,"user_tz":-330,"elapsed":2162,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn as skl\n","import sklearn.datasets as datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_percentage_error"]},{"cell_type":"code","source":["reg_dataset = datasets.make_regression(n_samples=1000, n_features=100, n_informative=10, n_targets=1, shuffle=True, random_state=42)\n","X = reg_dataset[0]\n","y = reg_dataset[1]"],"metadata":{"id":"9hgUxNvk2_lG","executionInfo":{"status":"ok","timestamp":1666248674714,"user_tz":-330,"elapsed":16,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X_train,X_test,y_train,y_test = train_test_split(X,y,train_size = .80,shuffle= True, random_state = 42)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYVM1jDy3rsO","executionInfo":{"status":"ok","timestamp":1666248674714,"user_tz":-330,"elapsed":14,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}},"outputId":"007c17a8-e800-4887-82c4-2449beb31c43"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(800, 100)\n","(200, 100)\n","(800,)\n","(200,)\n"]}]},{"cell_type":"code","source":["standardscalar = StandardScaler()\n","standardscalar.fit(X_train)\n","standardscalar.transform(X_train)\n","standardscalar.transform(X_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLja6Gf44BQu","executionInfo":{"status":"ok","timestamp":1666248674715,"user_tz":-330,"elapsed":11,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}},"outputId":"78aaa108-d307-469e-bc67-d20c33b56967"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.75070067, -0.3481925 , -1.17378933, ..., -1.90940973,\n","         0.46984207,  0.62394679],\n","       [ 0.84896602,  0.31452426, -0.21710923, ...,  1.1251983 ,\n","         1.96654319,  0.40548378],\n","       [ 0.66993726,  1.23443248,  0.99119684, ..., -0.464584  ,\n","         1.02210749,  1.26164339],\n","       ...,\n","       [-0.62975098,  0.57138191,  1.33530621, ..., -1.29090787,\n","        -1.27575008,  0.22965224],\n","       [-0.84372868, -1.52121785,  0.47398936, ..., -0.86898062,\n","         1.74069389, -0.06974126],\n","       [ 0.29565289,  0.92703245,  0.36029547, ..., -0.17267686,\n","         0.77579379, -1.19959866]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# lets write code for linear regression"],"metadata":{"id":"-ZO52CVV5vck"}},{"cell_type":"code","source":["class LinearRegression:\n","\n","\t\"\"\" Linear Regression with multiple features \"\"\"\n","\n","\tdef __init__(self, learning_rate = 1e-3, max_iter = 1000):\n","\n","\t\tself.num_feats = int\n","\t\tself.train_size = int\n","\t\tself.weights = np.array \n","\t\tself.y_train = np.array \n","\t\tself.input_matrix = np.array\n","\n","\t\tself.learning_rate = learning_rate   #Learning rate for gradient descent\n","\t\tself.max_iter = max_iter \t#Number of iterations to run gradient descent\n","\t\tself.cost_threshold = 0.1 * learning_rate  #stopping criterion for gradien descent\n","\n","\tdef fit(self, X, y):\n","\n","\t\t\"\"\"\n","\t\t\tAdjust weights to training data\n","\t\t\"\"\"\n","\n","\t\tself.train_size = X.shape[0]\n","\t\tself.num_feats = X.shape[1]\n","\t\tself.input_matrix = np.append(X, np.ones(self.train_size).reshape(-1, 1), axis = 1)   #Add Column with Ones for intercept term \n","\t\tself.y_train = y\n","\t\tself.weights = np.zeros(self.num_feats + 1) #Extra +1 for the intercept\n","\n","\n","\t\t#optimize weights\n","\t\tprev_cost = float(\"inf\")\n","\t\tfor i in range(self.max_iter):\n","\t\t\tcost = self._update_weights()\n","\n","\t\t\tif i%100 ==0 or i == self.max_iter:\n","\t\t\t\tprint(\"Cost after {} iterations is: {}\".format(i, cost))\n","\t\t\tif abs(prev_cost -cost) < self.cost_threshold*prev_cost:\n","\t\t\t\tprint(\"Cost after {} iterations is: {}\".format(i, cost))\n","\t\t\t\tbreak\n","\t\t\tprev_cost = cost\n","\n","\tdef _update_weights(self):\n","\n","\t\t\"\"\"\n","\t\t\tCost Function:\n","\t\t\t\tl(w) = (1/n) * (((y - wX)^2) \n","\t\t\tGradient:\n","\t\t\t\tdelta_w = dl/dw = (2/n)*( ((y - wX)*(-X))\n","\t\t\t\t\t\t\t\n","\t\t\t\t\t\t\t (or)\n","\t\t\t\tdelta_w = dl/dw = (2/n)*( ((wX - y)*(X)) \n","\t\t\tGradient Descent:\n","\t\t\t\tw = w - (learning_rate * delta_w)\n","\t\t\"\"\"\n","\n","\t\ty_pred = (self.weights * self.input_matrix).sum(axis = 1)  # y_pred = wX\n","\n","\t\tcost = (1/self.train_size) * (((self.y_train - y_pred) ** 2).sum(axis = 0))  \n","\n","\t\terr = (y_pred - self.y_train).reshape(-1, 1)  # err = wX - y\n","\n","\t\tdelta_w = (2/self.train_size) * ((err * self.input_matrix).sum(axis = 0)) #delta_w = (2/n)*( (wX - y)*(X)) \n","\n","\t\tself.weights = self.weights - (self.learning_rate * delta_w) \n","\n","\t\treturn cost\n","\n","\n","\tdef predict(self, X):\n","\n","\t\t\"\"\" Make predictions on given X using trained model \"\"\"\n","\n","\t\tsize = X.shape[0]\n","\t\tX = np.append(X, np.ones(size).reshape(-1, 1), axis = 1)\n","\n","\t\ty_pred = (self.weights * X).sum(axis = 1)\n","\n","\t\treturn y_pred "],"metadata":{"id":"okUltqny5vOC","executionInfo":{"status":"ok","timestamp":1666248674715,"user_tz":-330,"elapsed":9,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# lets fit and predict on the model\n"],"metadata":{"id":"fV9w78Lz62kK"}},{"cell_type":"code","source":["lin_reg = LinearRegression(learning_rate = 1e-3, max_iter = 5000)\n","lin_reg.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBXqBPzX5Z1q","executionInfo":{"status":"ok","timestamp":1666248676707,"user_tz":-330,"elapsed":2000,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}},"outputId":"d638c771-26b1-4555-8fc9-0d5026b6f661"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cost after 0 iterations is: 24752.939027679462\n","Cost after 100 iterations is: 16089.58998020282\n","Cost after 200 iterations is: 10649.843615559808\n","Cost after 300 iterations is: 7174.625456539455\n","Cost after 400 iterations is: 4915.864065326695\n","Cost after 500 iterations is: 3422.6335649062535\n","Cost after 600 iterations is: 2419.055491024841\n","Cost after 700 iterations is: 1733.7712692324474\n","Cost after 800 iterations is: 1258.7036832302888\n","Cost after 900 iterations is: 924.6368822719228\n","Cost after 1000 iterations is: 686.5657787657841\n","Cost after 1100 iterations is: 514.7883539620626\n","Cost after 1200 iterations is: 389.4157356216081\n","Cost after 1300 iterations is: 296.9421014814182\n","Cost after 1400 iterations is: 228.0720258439568\n","Cost after 1500 iterations is: 176.32545810187213\n","Cost after 1600 iterations is: 137.12990189314425\n","Cost after 1700 iterations is: 107.22181827319972\n","Cost after 1800 iterations is: 84.24683015180845\n","Cost after 1900 iterations is: 66.48936497415818\n","Cost after 2000 iterations is: 52.68762550397085\n","Cost after 2100 iterations is: 41.90549455217773\n","Cost after 2200 iterations is: 33.44287614617922\n","Cost after 2300 iterations is: 26.772280932925813\n","Cost after 2400 iterations is: 21.49352734704912\n","Cost after 2500 iterations is: 17.301078943892186\n","Cost after 2600 iterations is: 13.960284137346385\n","Cost after 2700 iterations is: 11.289947738272549\n","Cost after 2800 iterations is: 9.149446810627232\n","Cost after 2900 iterations is: 7.429136005785058\n","Cost after 3000 iterations is: 6.043153392813781\n","Cost after 3100 iterations is: 4.923991490745009\n","Cost after 3200 iterations is: 4.018375727857245\n","Cost after 3300 iterations is: 3.284117862746579\n","Cost after 3400 iterations is: 2.68770110086006\n","Cost after 3500 iterations is: 2.2024176443361405\n","Cost after 3600 iterations is: 1.806925690697561\n","Cost after 3700 iterations is: 1.484126600866044\n","Cost after 3800 iterations is: 1.2202876753142184\n","Cost after 3900 iterations is: 1.0043542245520904\n","Cost after 4000 iterations is: 0.827408174908679\n","Cost after 4100 iterations is: 0.6822405792745774\n","Cost after 4200 iterations is: 0.5630130136671759\n","Cost after 4300 iterations is: 0.4649885903790617\n","Cost after 4400 iterations is: 0.38431768417926104\n","Cost after 4500 iterations is: 0.3178667986197063\n","Cost after 4600 iterations is: 0.2630815518894464\n","Cost after 4700 iterations is: 0.21787672607012742\n","Cost after 4800 iterations is: 0.18054784166827817\n","Cost after 4900 iterations is: 0.14969989688470123\n"]}]},{"cell_type":"code","source":["print('Linear Regression Model Coefficients (W): {}'.format(lin_reg.weights[:-1]))\n","print('Linear Regression Model Intercept (b): {}'.format(lin_reg.weights[-1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R627Vm8k68iN","executionInfo":{"status":"ok","timestamp":1666248676707,"user_tz":-330,"elapsed":10,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}},"outputId":"a2a11841-f2fb-425d-935b-471a68f11a99"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Model Coefficients (W): [ 4.82293823e+01 -3.73555364e-02  2.02705048e-02 -1.35986598e-01\n","  8.32801336e-02  1.12663535e-02 -1.15921617e-02  1.71066426e-02\n","  9.14474060e-03 -2.02269526e-02 -5.83827922e-02 -2.12861391e-02\n"," -7.05958943e-02  1.94315579e-02  8.27687196e+01  2.12640114e-03\n","  5.59259880e-02  7.82890440e+01  3.55943304e-02  4.02046537e-02\n","  9.66546200e-02 -5.36181117e-03  3.53885758e-02 -2.18655896e-02\n"," -2.76309478e-02 -7.30671940e-02  1.87158956e+00  2.79897754e-02\n","  1.14003261e-02  3.54715059e-02 -3.56067973e-03  5.50174271e-02\n"," -7.33437331e-02 -1.27835124e-02 -3.34085679e-02 -6.03063045e-02\n","  2.12262517e-02 -7.65986660e-02 -3.95743055e-04  1.41059099e-02\n"," -2.45605421e-02 -1.90800305e-02  5.69584117e+01  2.80131646e-02\n"," -4.79975328e-03  1.10451373e-02  2.82987803e-02 -1.53223315e-02\n","  8.33374862e-02  2.94664079e-02  1.60562138e-02  9.11381723e-03\n","  2.81750116e-02 -5.21291707e-02 -3.48727420e-02  6.55683730e-02\n","  3.20355072e-02  2.94640966e+01 -1.48969099e-02  1.20340683e-02\n","  1.93201506e+01 -4.87882302e-03 -7.28275825e-02  5.53549522e-02\n"," -6.62653738e-02  4.80840720e-02  3.17379071e-02  8.85000079e+00\n"," -6.56992679e-02  6.19872231e-02 -2.68267419e-02  7.54680473e-02\n","  7.43090239e-03  2.58787459e-02  1.05234934e-02 -5.23042344e-02\n","  1.01045304e-02 -2.36062486e-02 -4.10124023e-02  2.80653911e-02\n"," -1.01646221e-01 -2.48649443e-02 -1.57369157e-01 -1.30094300e-02\n","  2.53876818e+01  1.82458751e-02  1.67556522e-02 -4.27580383e-02\n"," -2.18592055e-02 -1.31342051e-02 -4.09354756e-02 -2.28786214e-02\n"," -2.22113751e-02  3.57365385e-02 -3.19693295e-02  6.81685722e+01\n"," -5.60688827e-02  9.19984078e-02 -6.42103575e-02 -7.86730856e-02]\n","Linear Regression Model Intercept (b): -0.06257647343267524\n"]}]},{"cell_type":"markdown","source":["# lets see the MAPE of the model"],"metadata":{"id":"Z3Z3k4jr7fPf"}},{"cell_type":"code","source":["#Evaluating Model through MAPE\n","print(\"\\nMean Absolute Percentage Error(for train data): {}\".format(mean_absolute_percentage_error(y_train, lin_reg.predict(X_train))))\n","print(\"Mean Absolute Percentage Error(for test data): {}\".format(mean_absolute_percentage_error(y_test, lin_reg.predict(X_test))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Por4q8x87ZQP","executionInfo":{"status":"ok","timestamp":1666248676708,"user_tz":-330,"elapsed":8,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}},"outputId":"85fec8f9-b0c2-4f8d-c2a0-25392e3c5da4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Mean Absolute Percentage Error(for train data): 0.007574896963898376\n","Mean Absolute Percentage Error(for test data): 0.010813259071298898\n"]}]},{"cell_type":"markdown","source":["### yes we got the best model because the data is simulated on real dataset we have lot of optimisation to do."],"metadata":{"id":"wjj4rGwR7_3W"}},{"cell_type":"code","source":[],"metadata":{"id":"whS4Qcad7xfI","executionInfo":{"status":"ok","timestamp":1666248676709,"user_tz":-330,"elapsed":7,"user":{"displayName":"santhosh kurnapally","userId":"15491120331264307379"}}},"execution_count":9,"outputs":[]}]}